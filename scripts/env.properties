# env.properties

spark.flint.datasource.name=my_glue1
# or "streaming". picks one of two top-level branches in FlintREPL.main
# most likely need a different option list if running a streaming job
spark.flint.job.type=interactive
spark.flint.job.sessionId=10
spark.flint.job.requestIndex=flint_ql_sessions
# jobs exit during startup if their ID is in this comma-separated list
#spark.flint.deployment.excludeJobs=00fer5qo32fa080q
# If we're running this ourselves, we probably want this to be near-infinite
spark.flint.job.inactivityLimitMillis=5000
# A SessionCatalog seems to be the data structure where metadata for
# databases, tables, views, etc are stored. This tells Flint to use
# the V2 catalog (instead of V1?) (what's the difference?).
spark.sql.catalog.my_glue1=org.opensearch.sql.FlintDelegatingSessionCatalog
# Where the driver will be located, recall the Cluster Manager doc
spark.master=local
# IP address (or URL?) of OS host to use -- defaults to the Docker container's IP.
# Probably can be localhost?
spark.datasource.flint.host=ec2-54-245-164-117.us-west-2.compute.amazonaws.com
spark.database.flint.port=9200
# Whether to force OpenSearch refreshes to happen before reporting job results.
# Can also be "wait_for" or "false".
spark.datasource.flint.write.refresh_policy=true
# Spark doesn't actually run commands immediately,
# it polls every ${qLEF}ms for new commands.
# This polling is also where we check for the inactivity timeout.
spark.flint.job.queryLoopExecutionFrequency=100

SERVERLESS_EMR_JOB_ID=00ff4o3b5091080q
SERVERLESS_EMR_VIRTUAL_CLUSTER_ID=00feq82b752mbt0p
